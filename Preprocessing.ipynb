{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFzNFQD4Qlvn",
        "outputId": "dbb4fbc0-b370-4b0e-fca3-7c4bd1e8f436"
      },
      "source": [
        "!pip install benepar\n",
        "!pip install cython numpy\n",
        "!pip install Keras\n",
        "!pip install wordninja\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.7/dist-packages (from benepar) (3.2.5)\n",
            "Requirement already satisfied: spacy>=2.0.9 in /usr/local/lib/python3.7/dist-packages (from benepar) (2.2.4)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from benepar) (1.8.1+cu101)\n",
            "Collecting torch-struct>=0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/8c/775b7e141f11d509d59d0d2d801337ff3ad0203bc1a40335ea83e1161ba7/torch_struct-0.5-py3-none-any.whl\n",
            "Collecting tokenizers>=0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 31.6MB/s \n",
            "\u001b[?25hCollecting transformers[tokenizers,torch]>=4.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 37.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from benepar) (3.12.4)\n",
            "Collecting sentencepiece>=0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.2->benepar) (1.15.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (56.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (7.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->benepar) (3.7.4.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 39.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (3.10.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (20.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.0.9->benepar) (2020.12.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[tokenizers,torch]>=4.2.2->benepar) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[tokenizers,torch]>=4.2.2->benepar) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[tokenizers,torch]>=4.2.2->benepar) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers[tokenizers,torch]>=4.2.2->benepar) (2.4.7)\n",
            "Building wheels for collected packages: benepar\n",
            "  Building wheel for benepar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for benepar: filename=benepar-0.2.0-cp37-none-any.whl size=37647 sha256=53aafaa935f5f6b89425f2672bd61927a29137de23e04fc8019f4f3882942b00\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/90/28/513063023646df7774be9401c440a5f13b48bdbab15a67fc42\n",
            "Successfully built benepar\n",
            "Installing collected packages: torch-struct, tokenizers, sacremoses, transformers, sentencepiece, benepar\n",
            "Successfully installed benepar-0.2.0 sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.10.2 torch-struct-0.5 transformers-4.5.1\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (0.29.22)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras) (1.15.0)\n",
            "Collecting wordninja\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/15/abe4af50f4be92b60c25e43c1c64d08453b51e46c32981d80b3aebec0260/wordninja-2.0.0.tar.gz (541kB)\n",
            "\u001b[K     |████████████████████████████████| 542kB 18.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-cp37-none-any.whl size=541554 sha256=f102d4a7cd87ad51820124bc5000d8e39eb51c4a1d4df8b0d0342b537733bcaa\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/46/06/9b6d10ed02c85e93c3bb33ac50e2d368b2586248f192a2e22a\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpHo29_OP-tY",
        "outputId": "0a18f84b-783f-4234-c30c-e4f50fe1c74c"
      },
      "source": [
        "import pandas as pd \n",
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk import Tree\n",
        "from nltk.draw.tree import TreeView\n",
        "import os\n",
        "from spacy import displacy\n",
        "import spacy\n",
        "from collections import Counter\n",
        "import en_core_web_sm\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import wordninja\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nlp = en_core_web_sm.load()\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUQFVTn-BKg5",
        "outputId": "e060efa4-ab6a-4467-b5a4-652025ed4e90"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ak1yeF3BM2d",
        "outputId": "fc0e87bb-16eb-4194-ecb2-55bdd049e4ae"
      },
      "source": [
        "path_data = '/content/drive/My Drive/'\n",
        "path = os.path.join(path_data, 'stock_data.csv')\n",
        "datastock = pd.read_csv(path,encoding='latin-1',names=['News', 'Sentiment'], header=0)\n",
        "datastock.Sentiment[datastock.Sentiment == 1] = 'positive'\n",
        "datastock.Sentiment[datastock.Sentiment == -1] = 'negative'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0-sC3gbQtvS"
      },
      "source": [
        "path_data = '/content/drive/My Drive/Colab Notebooks/financial news'\n",
        "path = os.path.join(path_data, 'all-data.csv')\n",
        "datakaggle = pd.read_csv(path,encoding='latin-1',names=['Sentiment', 'News'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "PI8rRLEeCYlT",
        "outputId": "aafae1a1-16be-4f10-c996-adbf1c5dc34e"
      },
      "source": [
        "data= pd.concat([datastock, datakaggle], ignore_index = True)\n",
        "data.reset_index()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>News</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>MNTA Over 12.00</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>OI  Over 21.37</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10632</th>\n",
              "      <td>10632</td>\n",
              "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10633</th>\n",
              "      <td>10633</td>\n",
              "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10634</th>\n",
              "      <td>10634</td>\n",
              "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10635</th>\n",
              "      <td>10635</td>\n",
              "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10636</th>\n",
              "      <td>10636</td>\n",
              "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10637 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       index                                               News Sentiment\n",
              "0          0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...  positive\n",
              "1          1  user: AAP MOVIE. 55% return for the FEA/GEED i...  positive\n",
              "2          2  user I'd be afraid to short AMZN - they are lo...  positive\n",
              "3          3                                  MNTA Over 12.00    positive\n",
              "4          4                                   OI  Over 21.37    positive\n",
              "...      ...                                                ...       ...\n",
              "10632  10632  LONDON MarketWatch -- Share prices ended lower...  negative\n",
              "10633  10633  Rinkuskiai 's beer sales fell by 6.5 per cent ...   neutral\n",
              "10634  10634  Operating profit fell to EUR 35.4 mn from EUR ...  negative\n",
              "10635  10635  Net sales of the Paper segment decreased to EU...  negative\n",
              "10636  10636  Sales in Finland decreased by 10.5 % in Januar...  negative\n",
              "\n",
              "[10637 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2aoYh6enGf5",
        "outputId": "53b0e639-1109-4ff1-e0fb-9e578371b8ab"
      },
      "source": [
        "# !pip install english-words\n",
        "# from english_words import english_words_lower_alpha_set#english_words_set\n",
        "# def splitConcatenatedWords(word):\n",
        "#   new\n",
        "#   if len(token[0])>1 and len(wordninja.split(token[0]))>1:\n",
        "#     for splitword in wordninja.split(token[0]):\n",
        "#       if splitword in english_words_set is True:\n",
        "        \n",
        "#       else:\n",
        "          "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: english-words in /usr/local/lib/python3.7/dist-packages (1.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5kf1sVxVE7W"
      },
      "source": [
        "Sentence Object\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYdMmBqqQ0Sz"
      },
      "source": [
        "class Sentence:\n",
        "  def __init__(self):\n",
        "    self.words = []\n",
        "    self.wholeSentence = None\n",
        "    self.sentiment = None\n",
        "    self.tree = None\n",
        "    self.NerTag = None\n",
        "\n",
        "  def appendWords(self, word): \n",
        "    self.words.append(word) \n",
        "\n",
        "class Word:\n",
        "  def __init__(self):\n",
        "    self.word = None\n",
        "    self.lemma = None\n",
        "    self.synsetName = None\n",
        "    self.synsetDefinition = None\n",
        "    self.posTag = None\n",
        "    self.grammarTag = None\n",
        "    self.synonyma = []\n",
        "    self.antonyma = None\n",
        "    self.negation = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tem4vBXsQ3B_"
      },
      "source": [
        "\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def get_first_sense(word, pos=None):\n",
        "    if pos:\n",
        "        synsets = wordnet.synsets(word,pos)\n",
        "    else:\n",
        "        synsets = wordnet.synsets(word)\n",
        "    if not synsets:\n",
        "      return None\n",
        "    else:\n",
        "      return synsets[0]\n",
        "\n",
        "data['Postag-Lemmatized Sentence'] = None\n",
        "data['Pos-Lem Sen without tags'] = None\n",
        "listofSentences = []\n",
        "for index,row in data.iterrows():\n",
        "  #inicializácia objektov\n",
        "  lm = WordNetLemmatizer()\n",
        "  sentenceObject = Sentence()\n",
        "\n",
        "  newEditedSentence = \"\"\n",
        "  taggedlematizedsentence = []\n",
        "\n",
        "\n",
        "  sentence = row['News']\n",
        "  sentenceObject.sentiment = row['Sentiment']\n",
        "  tokenized_sentence = text_to_word_sequence(sentence)\n",
        "  tagged_sentence = nltk.pos_tag(tokenized_sentence)\n",
        "\n",
        "  for token in tagged_sentence:\n",
        "    wordObject = Word()\n",
        "    best_synset = None\n",
        "    postag = get_wordnet_pos(token[1])\n",
        "\n",
        "    wordObject.word = token[0]\n",
        "    if postag is None or postag is '': # not supply tag in case of None\n",
        "      lemma = lm.lemmatize(token[0])\n",
        "      taggedlematizedsentence.append((lemma,token[1]))\n",
        "      newEditedSentence+=lemma + \" \"\n",
        "      best_synset = get_first_sense(lemma)\n",
        "      wordObject.lemma = lemma\n",
        "      wordObject.posTag = token[1]\n",
        "    else:\n",
        "      lemma = lm.lemmatize(token[0], postag) \n",
        "      taggedlematizedsentence.append((lemma,token[1])) # vráti sa mi lemma a pridam povodny postag nie ten ktory mam z wordnetu \n",
        "      best_synset = get_first_sense(lemma,postag)\n",
        "\n",
        "      newEditedSentence+=lemma + \" \"\n",
        "      wordObject.lemma = lemma\n",
        "      wordObject.posTag = token[1]\n",
        "\n",
        "    if best_synset is None:\n",
        "      #print(\"Slovo nema viac významov\") \n",
        "      wordObject.synsetName = None\n",
        "      wordObject.synsetDefinition = None\n",
        "      #TODO negation handling   \n",
        "    else:\n",
        "      wordObject.synsetName = best_synset.name()\n",
        "      wordObject.synsetDefinition = best_synset.definition()\n",
        "      for synlemma in best_synset.lemmas():\n",
        "\n",
        "        if synlemma.name() == lemma:\n",
        "          continue\n",
        "        else:\n",
        "          wordObject.synonyma.append(synlemma.name())\n",
        "        if synlemma.antonyms():\n",
        "          wordObject.antonyma = synlemma.antonyms()[0].name()\n",
        "          #print(wordObject.lemma,synlemma.antonyms()[0].name())\n",
        "\n",
        "\n",
        "    sentenceObject.appendWords(wordObject)\n",
        "  sentenceObject.wholeSentence = newEditedSentence\n",
        "  data.at[index,'Postag-Lemmatized Sentence'] = taggedlematizedsentence\n",
        "  data.at[index,'Pos-Lem Sen without tags'] = newEditedSentence\n",
        "  data.at[index,'Sentence-word object'] = sentenceObject\n",
        "  listofSentences.append(sentenceObject)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBWTx9Bg9vXk",
        "outputId": "4b066b9f-6ea7-4c09-888a-fa7007602259"
      },
      "source": [
        "count = 0\n",
        "for sentence in listofSentences:\n",
        "  for word in sentence.words:\n",
        "    count+=1\n",
        "print(len(listofSentences))\n",
        "print(len(data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10637\n",
            "10637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuBELNuEm5jN"
      },
      "source": [
        "## ***Constituency parsing(nie dependency)***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMvbX8NPQ6X2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64752ab-ae3b-461c-f47c-53a3be165996"
      },
      "source": [
        "data['Sentence-Regex-Tree'] = None\n",
        "\n",
        "chunkGram = r\"\"\"\n",
        "                       NP: {<DT>?<JJ>*<NN>}    #To extract Noun Phrases\n",
        "                       P: {<IN>}               #To extract Prepositions\n",
        "                       V: {<V.*>}              #To extract Verbs\n",
        "                       PP: {<P> <NP>}          #To extract Prepostional Phrases\n",
        "                       VP: {<V> <NP|PP>*}      #To extarct Verb Phrases\n",
        "                       \"\"\"\n",
        "for index,row in data.iterrows():\n",
        "  cp = nltk.RegexpParser(chunkGram)\n",
        "  result = cp.parse(row['Postag-Lemmatized Sentence'])\n",
        "  tree = Tree.fromstring(str(result))\n",
        "  data.at[index,'Sentence-Regex-Tree'] = tree\n",
        "\n",
        "  if index == 1: \n",
        "      tree.pretty_print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                                                                                                         S                                                                                                                                                   \n",
            "        _________________________________________________________________________________________________________________________________|_______________________________________________________________________________________________________________________________________________     \n",
            "       |           |       |       |       |      |       |      |        |         |       |        |            |          |           |             |        |          |            |      |           |              |               VP                          |                  |   \n",
            "       |           |       |       |       |      |       |      |        |         |       |        |            |          |           |             |        |          |            |      |           |              |        _______|____                       |                  |    \n",
            "       |           |       |       |       |      |       |      |        |         |       |        |            |          |           |             VP       |          |            |      |           PP             VP      |            PP                     |                  VP  \n",
            "       |           |       |       |       |      |       |      |        |         |       |        |            |          |           |             |        |          |            |      |       ____|_____         |       |        ____|_______               |                  |    \n",
            "       |           |       |       |       |      |       |      |        |         |       |        |            |          |           |             V        P          NP           P      P      P          NP       V       V       P            NP             NP                 V   \n",
            "       |           |       |       |       |      |       |      |        |         |       |        |            |          |           |             |        |      ____|_____       |      |      |          |        |       |       |            |         _____|_______           |    \n",
            "technopolis/NNS plan/NNS to/TO stage/NNS no/DT less/JJR 100/CD 000/CD square/JJ meter/NNS to/TO company/NNS technology/NNS and/CC telecommunicatio develop/VB in/IN an/DT     area/NN of/IN than/IN in/IN     order/NN host/VB work/VBG in/IN     computer/NN the/DT     statement/NN say/VBD\n",
            "                                                                                                                                       n/NNS                                                                                                                                                 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRMVSU2cm9pg"
      },
      "source": [
        "*Dependency* parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDkOuOG7RF97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "d75ec078-e9d3-4067-e226-f2e68a421803"
      },
      "source": [
        "\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "for index,row in data.iterrows():\n",
        "  sentence = sp(row['News'])\n",
        "  # print(sentence)\n",
        "  if index < 1 :\n",
        "    displacy.render(sentence, style='dep',jupyter=True,  options={'distance': 85}) # displacy.render  & jupyter=True, -pridat, ked chcem aby to zobrazilo v notebooku a nie na na novej html stranke"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"897979294bbf4482b8d57eea016b4598-0\" class=\"displacy\" width=\"1920\" height=\"392.0\" direction=\"ltr\" style=\"max-width: none; height: 392.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">According</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"135\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"135\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"220\">Gran ,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"220\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"305\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"305\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"390\">company</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"390\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"475\">has</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"475\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"560\">no</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"560\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"645\">plans</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"645\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"730\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"730\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"815\">move</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"815\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"900\">all</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"900\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"985\">production</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"985\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1070\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1070\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1155\">Russia ,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1155\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1240\">although</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1240\">SCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1325\">that</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1325\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1410\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1410\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1495\">where</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1495\">ADV</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1580\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1580\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1665\">company</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1665\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1750\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1750\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"302.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1835\">growing .</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1835\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-0\" stroke-width=\"2px\" d=\"M70,257.0 C70,44.5 470.0,44.5 470.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,259.0 L62,247.0 78,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-1\" stroke-width=\"2px\" d=\"M70,257.0 C70,214.5 110.0,214.5 110.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M110.0,259.0 L118.0,247.0 102.0,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-2\" stroke-width=\"2px\" d=\"M155,257.0 C155,214.5 195.0,214.5 195.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M195.0,259.0 L203.0,247.0 187.0,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-3\" stroke-width=\"2px\" d=\"M325,257.0 C325,214.5 365.0,214.5 365.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M325,259.0 L317,247.0 333,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-4\" stroke-width=\"2px\" d=\"M410,257.0 C410,214.5 450.0,214.5 450.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M410,259.0 L402,247.0 418,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-5\" stroke-width=\"2px\" d=\"M580,257.0 C580,214.5 620.0,214.5 620.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M580,259.0 L572,247.0 588,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-6\" stroke-width=\"2px\" d=\"M495,257.0 C495,172.0 625.0,172.0 625.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M625.0,259.0 L633.0,247.0 617.0,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-7\" stroke-width=\"2px\" d=\"M750,257.0 C750,214.5 790.0,214.5 790.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750,259.0 L742,247.0 758,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-8\" stroke-width=\"2px\" d=\"M665,257.0 C665,172.0 795.0,172.0 795.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M795.0,259.0 L803.0,247.0 787.0,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-9\" stroke-width=\"2px\" d=\"M920,257.0 C920,214.5 960.0,214.5 960.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M920,259.0 L912,247.0 928,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-10\" stroke-width=\"2px\" d=\"M835,257.0 C835,172.0 965.0,172.0 965.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M965.0,259.0 L973.0,247.0 957.0,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-11\" stroke-width=\"2px\" d=\"M835,257.0 C835,129.5 1055.0,129.5 1055.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1055.0,259.0 L1063.0,247.0 1047.0,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-12\" stroke-width=\"2px\" d=\"M1090,257.0 C1090,214.5 1130.0,214.5 1130.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1130.0,259.0 L1138.0,247.0 1122.0,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-13\" stroke-width=\"2px\" d=\"M1260,257.0 C1260,172.0 1390.0,172.0 1390.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1260,259.0 L1252,247.0 1268,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-14\" stroke-width=\"2px\" d=\"M1345,257.0 C1345,214.5 1385.0,214.5 1385.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1345,259.0 L1337,247.0 1353,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-15\" stroke-width=\"2px\" d=\"M495,257.0 C495,2.0 1410.0,2.0 1410.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1410.0,259.0 L1418.0,247.0 1402.0,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-16\" stroke-width=\"2px\" d=\"M1515,257.0 C1515,87.0 1825.0,87.0 1825.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1515,259.0 L1507,247.0 1523,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-17\" stroke-width=\"2px\" d=\"M1600,257.0 C1600,214.5 1640.0,214.5 1640.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1600,259.0 L1592,247.0 1608,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-18\" stroke-width=\"2px\" d=\"M1685,257.0 C1685,172.0 1815.0,172.0 1815.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1685,259.0 L1677,247.0 1693,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-19\" stroke-width=\"2px\" d=\"M1770,257.0 C1770,214.5 1810.0,214.5 1810.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1770,259.0 L1762,247.0 1778,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-897979294bbf4482b8d57eea016b4598-0-20\" stroke-width=\"2px\" d=\"M1430,257.0 C1430,44.5 1830.0,44.5 1830.0,257.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-897979294bbf4482b8d57eea016b4598-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1830.0,259.0 L1838.0,247.0 1822.0,247.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgyd5uVYRND2"
      },
      "source": [
        "NER taggs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7EMXQx2ROXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52daab4-2623-40ff-eb4f-bc62f6e99333"
      },
      "source": [
        "print(data['News'][1])\n",
        "daco = dict([(str(x), x.label_) for x in nlp(str(data['News'][1])).ents])\n",
        "print(daco)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .\n",
            "{'Technopolis': 'GPE', '100,000 square meters': 'QUANTITY'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  'with `validate_args=False` to turn off validation.')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kK83JYUERRsW"
      },
      "source": [
        "Experimental constituent-based analysis and dependency parsing \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVj0y-8CRQr6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26436178-80db-43a1-e3a3-b0f0c34aff43"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install benepar\n",
        "import benepar\n",
        "benepar.download('benepar_en3')\n",
        "from benepar.spacy_plugin import BeneparComponent\n",
        "import benepar, spacy\n",
        "\n",
        "# Loading spaCy’s en model and adding benepar model to its pipeline\n",
        "nlp = spacy.load('en')\n",
        "if spacy.__version__.startswith('2'):\n",
        "        nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
        "else:\n",
        "        nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
        "data['Sentence-Benepar-Tree'] = None\n",
        "\n",
        "for index,row in data.iterrows():\n",
        "  # Generovanie stromu pre jednotliv=e texty \n",
        "  doc = nlp(row['Pos-Lem Sen without tags'])\n",
        "  sent = list(doc.sents)[0]\n",
        "\n",
        "  # print(sent._.parse_string)\n",
        "  bp = sent._.parse_string\n",
        "  benepartree = Tree.fromstring(str(bp))\n",
        "  data.at[index,'Sentence-Benepar-Tree'] = benepartree\n",
        "\n",
        "  if index == 1: \n",
        "\n",
        "    benepartree.pretty_print()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
            "Requirement already satisfied: benepar in /usr/local/lib/python3.7/dist-packages (0.2.0)\n",
            "Requirement already satisfied: torch-struct>=0.5 in /usr/local/lib/python3.7/dist-packages (from benepar) (0.5)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from benepar) (1.8.1+cu101)\n",
            "Requirement already satisfied: sentencepiece>=0.1.91 in /usr/local/lib/python3.7/dist-packages (from benepar) (0.1.95)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from benepar) (3.12.4)\n",
            "Requirement already satisfied: tokenizers>=0.9.4 in /usr/local/lib/python3.7/dist-packages (from benepar) (0.10.2)\n",
            "Requirement already satisfied: nltk>=3.2 in /usr/local/lib/python3.7/dist-packages (from benepar) (3.2.5)\n",
            "Requirement already satisfied: transformers[tokenizers,torch]>=4.2.2 in /usr/local/lib/python3.7/dist-packages (from benepar) (4.5.1)\n",
            "Requirement already satisfied: spacy>=2.0.9 in /usr/local/lib/python3.7/dist-packages (from benepar) (2.2.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->benepar) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->benepar) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->benepar) (56.0.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->benepar) (1.15.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (3.10.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (0.0.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[tokenizers,torch]>=4.2.2->benepar) (3.0.12)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.9->benepar) (1.0.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[tokenizers,torch]>=4.2.2->benepar) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[tokenizers,torch]>=4.2.2->benepar) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[tokenizers,torch]>=4.2.2->benepar) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[tokenizers,torch]>=4.2.2->benepar) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers[tokenizers,torch]>=4.2.2->benepar) (3.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[tokenizers,torch]>=4.2.2->benepar) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[tokenizers,torch]>=4.2.2->benepar) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers[tokenizers,torch]>=4.2.2->benepar) (2.4.7)\n",
            "[nltk_data] Downloading package benepar_en3 to /root/nltk_data...\n",
            "[nltk_data]   Package benepar_en3 is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributions/distribution.py:46: UserWarning: <class 'torch_struct.distributions.TreeCRF'> does not define `arg_constraints`. Please set `arg_constraints = {}` or initialize the distribution with `validate_args=False` to turn off validation.\n",
            "  'with `validate_args=False` to turn off validation.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                  S                                                                                                                                                                \n",
            "      ____________|___________                                                                                                                                                      \n",
            "     |                        VP                                                                                                                                                   \n",
            "     |        ________________|__________________________                                                                                                                           \n",
            "     |       |                                           S                                                                                                                         \n",
            "     |       |                                           |                                                                                                                          \n",
            "     |       |                                           VP                                                                                                                        \n",
            "     |       |     ______________________________________|__________________________                                                                                                \n",
            "     |       |    |                                                                 VP                                                                                             \n",
            "     |       |    |      ___________________________________________________________|___________                                                                                    \n",
            "     |       |    |     |         |                                                             NP                                                                                 \n",
            "     |       |    |     |         |                               ______________________________|____                                                                               \n",
            "     |       |    |     |         |                              |                                  SBAR                                                                           \n",
            "     |       |    |     |         |                              |                               ____|________                                                                      \n",
            "     |       |    |     |         |                              |                              |    |        S                                                                    \n",
            "     |       |    |     |         |                              |                              |    |        |                                                                     \n",
            "     |       |    |     |         |                              |                              |    |        VP                                                                   \n",
            "     |       |    |     |         |                              |                              |    |     ___|______                                                               \n",
            "     |       |    |     |         |                              |                              |    |    |          VP                                                            \n",
            "     |       |    |     |         |                              |                              |    |    |    ______|_________                                                     \n",
            "     |       |    |     |         |                              NP                             |    |    |   |                NP                                                  \n",
            "     |       |    |     |         |              ________________|____                          |    |    |   |             ___|__________                                          \n",
            "     |       |    |     |         |             |                     PP                        |    |    |   |            |              PP                                       \n",
            "     |       |    |     |         |             |         ____________|____                     |    |    |   |            |         _____|_____________                            \n",
            "     |       |    |     |         PP            |        |                 NP                   |    |    |   |            |        |                   NP                         \n",
            "     |       |    |     |      ___|____         |        |             ____|_______________     |    |    |   |            |        |             ______|_________________          \n",
            "     NP      |    |     |     |        NP       NP       |            QP            |      |    |    |    |   |            NP       |            NP             |         NP       \n",
            "     |       |    |     |     |        |     ___|___     |    ________|________     |      |    |    |    |   |       _____|___     |      ______|______        |         |         \n",
            "    NNS     VBP   TO    VB    IN       NN   DT      NN   IN  DT JJR   IN   CD  CD   JJ     NN   IN   NN   TO  VB     NN        NN   IN    NN            NN      CC        NN       \n",
            "     |       |    |     |     |        |    |       |    |   |   |    |    |   |    |      |    |    |    |   |      |         |    |     |             |       |         |         \n",
            "technopolis plan  to develop  in     stage  an     area  of  no less than 100 000 square meter  in order  to host company     work  in computer     technology and telecommunicatio\n",
            "                                                                                                                                                                          n        \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMlxnPMEjber"
      },
      "source": [
        "for index,sentence in enumerate(listofSentences):\n",
        "  for word in sentence.words:\n",
        "    print(word.lemma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSiLHj9_K1su"
      },
      "source": [
        "import pickle \n",
        "filehandler = open(\"/content/drive/My Drive/Sentence\", 'wb') \n",
        "pickle.dump(listofSentences, filehandler, pickle.HIGHEST_PROTOCOL)\n",
        "filehandler.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JMIqC-lWWVo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0192bd65-60b4-461e-e043-4432e2c3db37"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10637"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PaaZ2jOU4N-"
      },
      "source": [
        "data.to_csv('data_preprocessed.csv')\n",
        "!cp data_preprocessed.csv \"/content/drive/My Drive/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}